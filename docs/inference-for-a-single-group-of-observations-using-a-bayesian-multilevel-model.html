<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Inference for a ‘single group’ of observations using a Bayesian multilevel model | A Quick Introduction to Multilevel Bayesian Models for Linguistic Researchers</title>
  <meta name="description" content="Bayesian Models for Linguists" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Inference for a ‘single group’ of observations using a Bayesian multilevel model | A Quick Introduction to Multilevel Bayesian Models for Linguistic Researchers" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://santiagobarreda.com" />
  
  <meta property="og:description" content="Bayesian Models for Linguists" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Inference for a ‘single group’ of observations using a Bayesian multilevel model | A Quick Introduction to Multilevel Bayesian Models for Linguistic Researchers" />
  
  <meta name="twitter:description" content="Bayesian Models for Linguists" />
  

<meta name="author" content="Santiago Bareda" />


<meta name="date" content="2020-12-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="inspecting-a-single-sample-of-values.html"/>
<link rel="next" href="comparing-two-groups.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-29379Y1Q2X"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-29379Y1Q2X');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Models for Linguists</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="inspecting-a-single-sample-of-values.html"><a href="inspecting-a-single-sample-of-values.html"><i class="fa fa-check"></i><b>1</b> Inspecting a single sample of values</a>
<ul>
<li class="chapter" data-level="1.1" data-path="inspecting-a-single-sample-of-values.html"><a href="inspecting-a-single-sample-of-values.html#data-and-research-questions"><i class="fa fa-check"></i><b>1.1</b> Data and research questions</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="inspecting-a-single-sample-of-values.html"><a href="inspecting-a-single-sample-of-values.html#inspecting-the-central-location-and-spread-of-values"><i class="fa fa-check"></i><b>1.1.1</b> Inspecting the central location and spread of values</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="inspecting-a-single-sample-of-values.html"><a href="inspecting-a-single-sample-of-values.html#probability-distributions"><i class="fa fa-check"></i><b>1.2</b> Probability Distributions</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="inspecting-a-single-sample-of-values.html"><a href="inspecting-a-single-sample-of-values.html#the-normal-distribution"><i class="fa fa-check"></i><b>1.2.1</b> The normal distribution</a></li>
<li class="chapter" data-level="1.2.2" data-path="inspecting-a-single-sample-of-values.html"><a href="inspecting-a-single-sample-of-values.html#referring-to-the-normal-distribution-to-make-inferences"><i class="fa fa-check"></i><b>1.2.2</b> Referring to the normal distribution to make inferences</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="inspecting-a-single-sample-of-values.html"><a href="inspecting-a-single-sample-of-values.html#probabilities-of-events-and-likelihoods-of-parameters"><i class="fa fa-check"></i><b>1.3</b> Probabilities of events and likelihoods of parameters</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="inspecting-a-single-sample-of-values.html"><a href="inspecting-a-single-sample-of-values.html#making-inferences-using-likelihoods"><i class="fa fa-check"></i><b>1.3.1</b> Making inferences using likelihoods</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="inspecting-a-single-sample-of-values.html"><a href="inspecting-a-single-sample-of-values.html#bayesian-models"><i class="fa fa-check"></i><b>1.4</b> Bayesian models</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="inspecting-a-single-sample-of-values.html"><a href="inspecting-a-single-sample-of-values.html#what-are-regression-models"><i class="fa fa-check"></i><b>1.4.1</b> What are regression models?</a></li>
<li class="chapter" data-level="1.4.2" data-path="inspecting-a-single-sample-of-values.html"><a href="inspecting-a-single-sample-of-values.html#whats-bayesian-about-these-models"><i class="fa fa-check"></i><b>1.4.2</b> What’s ‘Bayesian’ about these models?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="inspecting-a-single-sample-of-values.html"><a href="inspecting-a-single-sample-of-values.html#posterior-distributions"><i class="fa fa-check"></i><b>1.5</b> Posterior distributions</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="inspecting-a-single-sample-of-values.html"><a href="inspecting-a-single-sample-of-values.html#sampling-from-the-posterior"><i class="fa fa-check"></i><b>1.5.1</b> Sampling from the posterior</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="inspecting-a-single-sample-of-values.html"><a href="inspecting-a-single-sample-of-values.html#plot-code"><i class="fa fa-check"></i><b>1.6</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><i class="fa fa-check"></i><b>2</b> Inference for a ‘single group’ of observations using a Bayesian multilevel model</a>
<ul>
<li class="chapter" data-level="2.1" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#data-and-research-questions-1"><i class="fa fa-check"></i><b>2.1</b> Data and research questions</a></li>
<li class="chapter" data-level="2.2" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#estimating-a-single-mean-with-the-brms-package"><i class="fa fa-check"></i><b>2.2</b> Estimating a single mean with the <code>brms</code> package</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#the-model"><i class="fa fa-check"></i><b>2.2.1</b> The model</a></li>
<li class="chapter" data-level="2.2.2" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#calling-the-brm-function"><i class="fa fa-check"></i><b>2.2.2</b> Calling the <code>brm</code> function</a></li>
<li class="chapter" data-level="2.2.3" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#interpreting-the-model-print-statement"><i class="fa fa-check"></i><b>2.2.3</b> Interpreting the model print statement</a></li>
<li class="chapter" data-level="2.2.4" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#seeing-the-samples"><i class="fa fa-check"></i><b>2.2.4</b> Seeing the samples</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#repeated-measures-data"><i class="fa fa-check"></i><b>2.3</b> Repeated measures data</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#multilevel-models"><i class="fa fa-check"></i><b>2.3.1</b> Multilevel models</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#estimating-a-multilevel-model-with-brms"><i class="fa fa-check"></i><b>2.4</b> Estimating a multilevel model with <code>brms</code></a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#the-model-1"><i class="fa fa-check"></i><b>2.4.1</b> The model</a></li>
<li class="chapter" data-level="2.4.2" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#fitting-the-model"><i class="fa fa-check"></i><b>2.4.2</b> Fitting the model</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#checking-model-convergence"><i class="fa fa-check"></i><b>2.5</b> Checking model convergence</a></li>
<li class="chapter" data-level="2.6" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#specifying-prior-probabilities"><i class="fa fa-check"></i><b>2.6</b> Specifying prior probabilities</a></li>
<li class="chapter" data-level="2.7" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#answering-our-research-questions"><i class="fa fa-check"></i><b>2.7</b> Answering our research questions</a></li>
<li class="chapter" data-level="2.8" data-path="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#plot-code-1"><i class="fa fa-check"></i><b>2.8</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html"><i class="fa fa-check"></i><b>3</b> Comparing two groups</a>
<ul>
<li class="chapter" data-level="3.1" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html#data-and-research-questions-2"><i class="fa fa-check"></i><b>3.1</b> Data and research questions</a></li>
<li class="chapter" data-level="3.2" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html#estimating-the-difference-two-means-with-brms"><i class="fa fa-check"></i><b>3.2</b> Estimating the difference two means with ‘brms’</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html#fitting-the-model-1"><i class="fa fa-check"></i><b>3.2.1</b> Fitting the model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html#contrasts"><i class="fa fa-check"></i><b>3.3</b> Contrasts</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html#treatment-coding"><i class="fa fa-check"></i><b>3.3.1</b> Treatment coding</a></li>
<li class="chapter" data-level="3.3.2" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html#sum-coding"><i class="fa fa-check"></i><b>3.3.2</b> Sum coding</a></li>
<li class="chapter" data-level="3.3.3" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html#comparison-of-sum-and-treatment-coding"><i class="fa fa-check"></i><b>3.3.3</b> Comparison of sum and treatment coding</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html#refitting-the-model-with-sum-coding"><i class="fa fa-check"></i><b>3.4</b> Refitting the model with sum coding</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html#fitting-the-model-2"><i class="fa fa-check"></i><b>3.4.1</b> Fitting the model</a></li>
<li class="chapter" data-level="3.4.2" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html#the-model-2"><i class="fa fa-check"></i><b>3.4.2</b> The model</a></li>
<li class="chapter" data-level="3.4.3" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html#interpreting-the-two-group-model"><i class="fa fa-check"></i><b>3.4.3</b> Interpreting the two-group model</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html#random-effects"><i class="fa fa-check"></i><b>3.5</b> ‘Random’ Effects</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html#random-effects-priors-and-pooling"><i class="fa fa-check"></i><b>3.5.1</b> Random effects, priors and pooling</a></li>
<li class="chapter" data-level="3.5.2" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html#inspecting-the-random-effects"><i class="fa fa-check"></i><b>3.5.2</b> Inspecting the random effects</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="comparing-two-groups.html"><a href="comparing-two-groups.html#but-what-does-it-all-mean"><i class="fa fa-check"></i><b>3.6</b> But what does it all mean?</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="http://www.santiagobarreda.com" target="blank">Written by Santiago Barreda</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Quick Introduction to Multilevel Bayesian Models for Linguistic Researchers</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> Inference for a ‘single group’ of observations using a Bayesian multilevel model</h1>
<p>In this chapter I am going to discuss how to use the <code>brms</code> package to estimate a population mean given a sample of data. For these models the data:</p>
<ul>
<li>can come from one speaker/subject or many speakers/subjects.</li>
<li>each speaker/subject can contribute multiple data points.</li>
<li>does not need to be ‘balanced’ or ‘complete’ across all subjects.</li>
</ul>
<p>The ‘traditional’ designs equivalent to these models are: one-sample t-test, and repeated-measures one-way ANOVA with only two groups. However, these models won’t be discussed in the chapter below.</p>
<div id="data-and-research-questions-1" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Data and research questions</h2>
<p>We are going to keep analyzing the female f0 data from the Hillenbrand et al. (1995) dataset.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb61-1" aria-hidden="true" tabindex="-1"></a>url1 <span class="ot">=</span> <span class="st">&quot;https://raw.githubusercontent.com/santiagobarreda&quot;</span></span>
<span id="cb61-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb61-2" aria-hidden="true" tabindex="-1"></a>url2 <span class="ot">=</span> <span class="st">&quot;/stats-class/master/data/h95_vowel_data.csv&quot;</span></span>
<span id="cb61-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb61-3" aria-hidden="true" tabindex="-1"></a>h95 <span class="ot">=</span> <span class="fu">read.csv</span> (<span class="fu">url</span>(<span class="fu">paste0</span> (url1, url2)))</span>
<span id="cb61-4"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb61-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-5"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="co"># select women only</span></span>
<span id="cb61-6"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb61-6" aria-hidden="true" tabindex="-1"></a>w <span class="ot">=</span> h95[h95<span class="sc">$</span>type <span class="sc">==</span> <span class="st">&#39;w&#39;</span>,]</span>
<span id="cb61-7"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb61-7" aria-hidden="true" tabindex="-1"></a><span class="co"># this is unique subject numbers across all groups</span></span>
<span id="cb61-8"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb61-8" aria-hidden="true" tabindex="-1"></a>w<span class="sc">$</span>uspeaker <span class="ot">=</span> <span class="fu">factor</span> (w<span class="sc">$</span>uspeaker)  </span>
<span id="cb61-9"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb61-9" aria-hidden="true" tabindex="-1"></a><span class="co"># select only the vector of interest</span></span>
<span id="cb61-10"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb61-10" aria-hidden="true" tabindex="-1"></a>f0s <span class="ot">=</span> w<span class="sc">$</span>f0</span></code></pre></div>
<p>We are going to try to address the same questions we talked about last week:</p>
<ol style="list-style-type: decimal">
<li><p>What is the average f0 of the whole <em>population</em> likely to be?</p></li>
<li><p>Can we set bounds on likely mean f0 values based on the data we collected?</p></li>
</ol>
<p>However, this time we are going to do this with a Bayesian multilevel model.</p>
</div>
<div id="estimating-a-single-mean-with-the-brms-package" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Estimating a single mean with the <code>brms</code> package</h2>
<p>The <code>brms</code> <a href="https://github.com/paul-buerkner/brms">Bayesian regression models</a> package in R lets you fit Bayesian models using the STAN probabilistic programming language using R. The package is really amazing and makes Bayesian multilevel modeling easy and accessible for anyone. It also includes a lot of helper functions that making with these models very convenient.</p>
<p><code>brms</code> should be installed in R so that the models described below will work. Make sure you have the latest version of R (and Rstudio) and the latest version of the `brms’ package installed. Sometimes using older versions can cause R to crash when fitting models.</p>
<div id="the-model" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> The model</h3>
<p>Model structures are expressed in R using a very specific syntax. Think of writing a model formula as writing a language within R. The good thing about learning to write models is then you can use this knowledge to describe your models in your work, and to interpret other people’s models.</p>
<p>The model formulas resemble regression equations to some extent, but there are some differences. Remember that regression models can be thought of like this:</p>
<p><span class="math display" id="eq:21">\[
y = \mu + \varepsilon
\tag{2.1}
\]</span></p>
<p>Which means that your observed variable <span class="math inline">\(y\)</span> is the sum of some of some average value (<span class="math inline">\(\mu\)</span>) and some random error <span class="math inline">\(\mu\)</span>. The random error is expected to be normally distributed with some unknown standard deviation (<span class="math inline">\(\varepsilon \sim \mathcal{N}(0,\sigma)\)</span>).</p>
<p>What we would really like is to understand orderly variation in <span class="math inline">\(\mu\)</span> by breaking it up into parts (<span class="math inline">\(\mathrm{x}_{1}, \mathrm{x}_{2},...\)</span>) when combined using some weights (<span class="math inline">\(a, b,...\)</span>).</p>
<p><span class="math display" id="eq:22">\[
y = a*\mathrm{x}_{1} + b*\mathrm{x}_{2} + ... + \varepsilon
\tag{2.2}
\]</span></p>
<p>‘Fitting’ a regression model consists of trying to ‘guess’ the values of the weighing factors (<span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> above), called the <em>model coefficients</em>. When we are only trying to estimate a single average, we don’t have any predictors to explain variation in <span class="math inline">\(\mu\)</span>. In fact, our model structure suggests we expect no variation in <span class="math inline">\(\mu\)</span>.</p>
<p>Mathematically, we can’t just say ‘we have no predictor’ since everything needs to be represented by a number. As a result, we use a ‘predictor’ with a value of 1 so that our regression equation is:</p>
<p><span class="math display" id="eq:23">\[
y = a*1 + \varepsilon
\tag{2.3}
\]</span></p>
<p>Now our model is trying to guess the value of a single parameter (<span class="math inline">\(a\)</span>), and we expect this parameter to be equal to <span class="math inline">\(\mu\)</span> since it is being multiplied by a ‘predictor’ with a constant value of 1.</p>
<p>This kind of model is called an ‘Intercept only’ model. Regression models are really about representing <em>differences</em>, differences between groups and across conditions. When you are encoding differences, you need an overall reference point. For example, saying that something is 5 miles north is only interpretable given some reference point. The ‘reference point’ used by your model is called your ‘Intercept’. Basically, our model consists <em>only</em> of a single reference point, the intercept. Also, when a predictor is just being multiplied by 1, we can just omit it from the regression model (but its still secretly there).</p>
<p>Our complete model is now:</p>
<p><span class="math display">\[
\begin{split}
f0 = Intercept + \varepsilon  \\
\varepsilon \sim \mathcal{N}(0,\sigma) \\
\end{split}
\]</span></p>
<p>Put in English, each line in the model says the following:</p>
<ul>
<li><p>f0 is equal to the sum the intercept and error.</p></li>
<li><p>the error is also drawn from a normal distribution with a mean of 0 and a standard deviation of <span class="math inline">\(\sigma\)</span>. This distribution represents all deviation in f0 around the mean f0 for the sample.</p></li>
</ul>
<p>Generally, model formulas in R have the form:</p>
<p><code>y ~ predictor</code></p>
<p>The variable we are interested in understanding (<span class="math inline">\(y\)</span>) goes on the left hand side, and on our predictors go on the right hand side, separated by a <span class="math inline">\(\sim\)</span>. Notice that the random term (<span class="math inline">\(\varepsilon\)</span>) is not included. The formula above can be read as ‘y is distributed according to some predictor’, which really means "we think there is systematic variation in our y variable that can be understood by considering its joint variation with our predictor variable(s).</p>
<p>For intercept only models, the number <code>1</code> is included in the model formula to indicate that a single constant value is being estimated. As a result, our model formula will have the form <code>f0 ~ 1</code>. This model could be said out loud like “we are trying to estimate the mean of f0” or “we are predicting mean f0 given only an intercept”.</p>
</div>
<div id="calling-the-brm-function" class="section level3" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Calling the <code>brm</code> function</h3>
<p>Below, I load the <code>brms</code> package, which contains the <code>brm</code> function. The <code>brm</code> function takes a model specification, data and some other information, and fits a model that estimates all the model parameters. Unless otherwise specified, <code>brm</code> assumes that the error component (<span class="math inline">\(\varepsilon\)</span>) of my model is normally distributed. The first argument in the function call is the model formula, and the second argument tells the function where to find the data. The other argument tell the function to estimates a single set of samples (chains = 1) using a single processor on your CPU (cores = 1). These arguments will be discussed more later.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># To ensure predictable results in examples, I will be using the same random  </span></span>
<span id="cb62-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="co"># seed throughout, and resetting it before running any &#39;random&#39; process.  </span></span>
<span id="cb62-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb62-4"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb62-4" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> brms<span class="sc">::</span><span class="fu">brm</span> (f0 <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> w, <span class="at">chains =</span> <span class="dv">1</span>, <span class="at">cores =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## Compiling Stan program...</code></pre>
<pre><code>## Start sampling</code></pre>
<pre><code>## 
## SAMPLING FOR MODEL &#39;98dae0f1caaef07c210aac2156c73749&#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 0 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.062 seconds (Warm-up)
## Chain 1:                0.042 seconds (Sampling)
## Chain 1:                0.104 seconds (Total)
## Chain 1:</code></pre>
<p>By default, <code>brms</code> takes 2000 samples, throwing out the first 1000 and returning the last 1000. The output above shows you that the sampler is working, and tells you about the progress as it works.</p>
<p>This is the last time I will be actually fitting a model in the code chunks. I am going to be relying on pre-fit models that you can load after downloading from the book GitHub. Models can be found in the folder corresponding to each chapter.</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="do">## load pre fit model</span></span>
<span id="cb66-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb66-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">readRDS</span> (<span class="st">&#39;2_model.RDS&#39;</span>)</span></code></pre></div>
</div>
<div id="interpreting-the-model-print-statement" class="section level3" number="2.2.3">
<h3><span class="header-section-number">2.2.3</span> Interpreting the model print statement</h3>
<p>We can evaluate the model name to show the default <code>brms</code> model print statement:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb67-1" aria-hidden="true" tabindex="-1"></a>model</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: f0 ~ 1 
##    Data: w (Number of observations: 576) 
## Samples: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 1000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   220.40      0.97   218.33   222.30 1.00      851      557
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    23.24      0.69    21.99    24.61 1.00      653      550
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Typing the model name into the console and hitting enter prints the information seen above. The first part just tells you technical details that we don’t have to worry about for now (though some are obvious).</p>
<pre><code>Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: f0 ~ 1 
   Data: w (Number of observations: 576) 
Samples: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup samples = 1000</code></pre>
<p>Next we see estimated effects for out predictors, in this case only an intercept. This is a ‘population’ level effect because is is shared by all observations in our sample, and not specific to any one observation.</p>
<pre><code>Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   220.40      0.97   218.33   222.30 1.00      851      557</code></pre>
<p>The information above provides the mean (Estimate) and standard deviation (Est. Error) of the posterior distribution of <span class="math inline">\(\mu\)</span> (Intercept). The values of <code>l-95% CI</code> and <code>u-95% CI</code> represent the upper and lower ‘95% credible intervals’ for the posterior distribution of this parameter.</p>
<p>The <em>x% credible interval</em> for a parameter is the smallest interval that encloses x% of the distribution. This parameter has an x% chance (0.x probability) of falling inside the x% credible interval. So, this means that there is a 95% probability that <span class="math inline">\(\mu\)</span> is between 218 and 222 Hz given our data and model structure.</p>
<p>Notice that the parameter estimate and intervals almost exactly match the estimate and intervals we obtain by referencing the theoretical likelihood function (discussed in Chapter 1):</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="do">## sample mean</span></span>
<span id="cb71-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span> (f0s)</span></code></pre></div>
<pre><code>## [1] 220.401</code></pre>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="do">## theoretical quantiles for likelihood of mean</span></span>
<span id="cb73-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span> (<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>), <span class="fu">mean</span> (f0s), <span class="fu">sd</span> (f0s) <span class="sc">/</span> <span class="fu">sqrt</span> (<span class="fu">length</span> (f0s) ) )</span></code></pre></div>
<pre><code>## [1] 218.5047 222.2974</code></pre>
<p>Our model also provides us an estimate of the error (<span class="math inline">\(\varepsilon\)</span>), under ‘Family Specific Parameters: sigma’. This estimate closely matches our sample standard deviation (<span class="math inline">\(s_{x}\)</span>) estimate of 23.2. In addition, we also get a 95% credible interval for this parameter (2.5% = 21.99, 97.5% = 24.61).</p>
<pre><code>Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma    23.24      0.69    21.99    24.61 1.00      653      550</code></pre>
<p>This last section is just boilerplate and contains some basic reminders. This text will look the same after all models.</p>
<pre><code>Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<div id="seeing-the-samples" class="section level3" number="2.2.4">
<h3><span class="header-section-number">2.2.4</span> Seeing the samples</h3>
<p>In Chapter 1 I discussed that samplers (like <code>brm</code>, or STAN) take samples of the posterior distributions of parameters given the data and model structure. It’s helpful to see that this is quite literally what is happening, and that the print statement above just summarizes the information contained in the posterior samples.</p>
<p>Below I get the posterior samples from the model. We have 1000 samples, as indicated in the model output above. The first column represents the model intercept, the middle column is the error, and the third column is a statistic related to model fit.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="do">## get posterior samples from model</span></span>
<span id="cb77-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb77-2" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">=</span> brms<span class="sc">::</span><span class="fu">posterior_samples</span> (model)</span>
<span id="cb77-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb77-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span> (samples)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    1000 obs. of  3 variables:
##  $ b_Intercept: num  221 221 220 222 220 ...
##  $ sigma      : num  22.1 21.9 23.2 21.9 22.9 ...
##  $ lp__       : num  -2635 -2635 -2634 -2637 -2634 ...</code></pre>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="do">## inspect values</span></span>
<span id="cb79-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span> (samples)</span></code></pre></div>
<pre><code>##   b_Intercept    sigma      lp__
## 1    220.7860 22.06961 -2634.851
## 2    220.5312 21.93719 -2635.160
## 3    219.6445 23.22390 -2633.588
## 4    222.3286 21.93414 -2637.392
## 5    219.5626 22.87259 -2633.785
## 6    221.2339 23.08532 -2633.672</code></pre>
<p>I can plot the individual samples for the mean parameter on the left below. On the right I plot a histogram of the same samples, superimposed with the theoretical distribution of the likelihood. Although this is not the posterior, with so many data points we expect our posterior to be dominated by the likelihood anyways.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb81-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span> (samples[,<span class="dv">1</span>], <span class="at">xlab =</span> <span class="st">&#39;Sample number&#39;</span>,<span class="at">ylab =</span> <span class="st">&#39;f0&#39;</span>,<span class="at">col=</span>teal,<span class="at">pch=</span><span class="dv">16</span>)</span>
<span id="cb81-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span> (samples[,<span class="dv">1</span>], <span class="at">freq =</span> <span class="cn">FALSE</span>, <span class="at">breaks =</span> <span class="dv">20</span>,<span class="at">main=</span><span class="st">&#39;&#39;</span>,<span class="at">xlab=</span><span class="st">&#39;f0&#39;</span>,<span class="at">col=</span>maroon)</span>
<span id="cb81-4"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb81-4" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dnorm</span> (x, <span class="fu">mean</span> (f0s), <span class="fu">sd</span> (f0s) <span class="sc">/</span> <span class="fu">sqrt</span> (<span class="fu">length</span> (f0s) )), <span class="at">add =</span> <span class="cn">TRUE</span>,</span>
<span id="cb81-5"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb81-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">4</span>, <span class="at">col =</span> yellow)</span></code></pre></div>
<p><img src="week-2_files/figure-html/unnamed-chunk-8-1.png" width="768" /></p>
<p>Recall that our model output provides information about expected values for the mean parameter:</p>
<pre><code>Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   220.40      0.97   218.33   222.30 1.00      851      557</code></pre>
<p>These simply correspond to the quantiles of the posterior samples!</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span> (samples[,<span class="dv">1</span>], <span class="fu">c</span>(.<span class="dv">025</span>, .<span class="dv">5</span>, .<span class="dv">975</span>))</span></code></pre></div>
<pre><code>##     2.5%      50%    97.5% 
## 218.3288 220.3997 222.3001</code></pre>
<p>There is no special status for these quantiles. We can check the values of other ones:</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span> (samples[,<span class="dv">1</span>], <span class="fu">c</span>(.<span class="dv">25</span>, .<span class="dv">75</span>))</span></code></pre></div>
<pre><code>##      25%      75% 
## 219.8043 221.0296</code></pre>
<p>Or even use the posterior distribution to find the probability that the mean parameter is over/under any arbitrary value:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span> (samples[,<span class="dv">1</span>] <span class="sc">&lt;</span> <span class="dv">221</span>)</span></code></pre></div>
<pre><code>## [1] 0.74</code></pre>
<p>For example, given the calculation above we can say that there is a 0.74 probability (a 74% chance) that the mean f0 for female speakers in this population is under 221 Hz, given our data and model structure. We come to this conclusion by finding that 74% of the posterior samples of the parameter of interest are below 221 Hz.</p>
</div>
</div>
<div id="repeated-measures-data" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Repeated measures data</h2>
<p>The model we fit above is a reasonable starting point, but it has many weaknesses. For example, it does not consider the fact that our data was produced by a fixed number of speakers, sampled from a population. It does not consider the variation in f0 inherent between speakers, treating this as ‘noise’.</p>
<p>Importantly, our data consists of 12 productions from each speaker in our sample, meaning we have ‘repeated measures’ data. Treating repeated measures data as if it were <em>not</em> repeated measures data can cause problems for our inferences. This is because it can give us a warped perspective of how much variability there really is in the sample.</p>
<p>For example, if I told you I had 1,000,000 samples of speech from male speakers from Los Angeles, you may be confident that I can estimate the average f0 male speakers from Los Angeles very accurately. But what if I told you that all these samples were from only three different people? You know instinctively that this makes my data less reliable.</p>
<p>The reason repeated-measures data can cause problems is because the measurements are correlated: multiple measurements from the same person are obviously going to be related to each other. If you measure the height of a tall person today, they will still be tall tomorrow. Because of this general principle, although we have 12 productions from each of 48 female speakers, we do not actually have 576=48*12 totally independent observations in our data.</p>
<p>This can be seen quite clearly below. The top panel shows the distribution of all our f0 measurements. The bottom panel shows speaker boxplots (one for each speaker’s data). If we were to ‘push down’ on the bottom panel and collapse all our boxplots into a single distribution, we would end up with the boxplot in the top panel.</p>
<p>These boxplots shows that each speaker has their own average f0, and that their productions tend to vary around their ‘natural average. As a result, we might have closer to 46 observations (one average value per speaker) than 576. For example, the ’outliers’ around 150 Hz may seem like huge ‘errors’ in the top plot. In the bottom plot we see that these productions all come from one speaker, and actually reflect her average f0. These are not errors but systematic between-speaker <em>variation</em>.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">1</span>)); <span class="fu">layout</span> (<span class="at">mat =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">heights =</span> <span class="fu">c</span>(.<span class="dv">3</span>,.<span class="dv">7</span>))</span>
<span id="cb89-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (f0s, <span class="at">main =</span> <span class="st">&quot;Overall Boxplot&quot;</span>, <span class="at">col=</span><span class="st">&quot;lavender&quot;</span>, </span>
<span id="cb89-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb89-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">horizontal =</span> <span class="cn">TRUE</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">140</span>,<span class="dv">320</span>)) </span>
<span id="cb89-4"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb89-4" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (f0 <span class="sc">~</span> uspeaker, <span class="at">data =</span> w, <span class="at">main =</span> <span class="st">&quot;Speaker Boxplots&quot;</span>, <span class="at">col=</span><span class="fu">c</span>(yellow,coral,</span>
<span id="cb89-5"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb89-5" aria-hidden="true" tabindex="-1"></a>         deepgreen,teal), <span class="at">horizontal =</span> <span class="cn">TRUE</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">140</span>,<span class="dv">320</span>)) </span>
<span id="cb89-6"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb89-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h =</span> <span class="fl">220.4</span>,<span class="at">lty=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">&#39;grey&#39;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="week-2_files/figure-html/unnamed-chunk-12-1.png" width="768" /></p>
<div id="multilevel-models" class="section level3" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Multilevel models</h3>
<p>In linguistics, and many other similar fields, almost all of our data is repeated measures data. The methods most commonly-used by linguists (e.g., experiments, interviews, corpora, … etc.) yield many observations per person, and typically all involve data from multiple people/sources. As a result, the analysis of this data requires that models be able to account for within <em>and</em> between speaker variation in our data. Multilevel models address the correlated nature of repeated measures data by estimating multiple sources of variation simultaneously.</p>
<p>Repeated-measures data leads to random variation in parameters that is <em>indistinguishable</em> from that of our ‘data’. To a large extent, whether something is a parameter or a data point depends somewhat on your perspective. For example, consider the figure below. The top left presents a histogram of all f0 measurements, while the top right presents a boxplot of the same. The bottom left presents the speaker boxplots (one per speaker), each of which resembles the overall boxplot in the top right. We can then zoom in on a single speaker’s productions (bottom right) and produce a histogram that suggests a normal distribution reminiscent in shape to the overall aggregated data (top left).</p>
<p>If you are trying to estimate a speaker’s mean f0, then the individual productions might be ‘data’ and the mean can be thought of as a ‘parameter’. If you were instead only interested in the population average, maybe now your subject mean is actually just a single data point, and the <em>population</em> mean is actually your ‘parameter’.</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">1</span>))</span>
<span id="cb90-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb90-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span> (w<span class="sc">$</span>f0, <span class="at">main =</span> <span class="st">&quot;Histogram of all f0&quot;</span>,<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">140</span>, <span class="dv">290</span>), <span class="at">freq =</span> <span class="cn">FALSE</span>,</span>
<span id="cb90-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb90-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">col=</span><span class="dv">4</span>)</span>
<span id="cb90-4"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (w<span class="sc">$</span>f0, <span class="at">main =</span> <span class="st">&quot;Boxplot of all f0&quot;</span>,<span class="at">col=</span>lavender)</span>
<span id="cb90-5"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb90-5" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (f0 <span class="sc">~</span> uspeaker, <span class="at">data =</span> w, <span class="at">main =</span> <span class="st">&quot;Speaker Boxplots&quot;</span>,<span class="at">col=</span>deepgreen) </span>
<span id="cb90-6"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb90-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">v =</span> <span class="dv">16</span>,<span class="at">lty=</span><span class="dv">3</span>)</span>
<span id="cb90-7"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb90-7" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span> (w<span class="sc">$</span>f0[w<span class="sc">$</span>uspeaker <span class="sc">==</span> <span class="dv">107</span>], <span class="at">main =</span> <span class="st">&quot;Histogram of speaker 107&quot;</span>,</span>
<span id="cb90-8"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb90-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">160</span>, <span class="dv">260</span>), <span class="at">freq =</span> <span class="cn">FALSE</span>,<span class="at">col=</span>yellow)</span></code></pre></div>
<p><img src="week-2_files/figure-html/unnamed-chunk-13-1.png" width="768" /></p>
<p>A multilevel model is able to simultaneously model independent variation at multiple ‘levels’. For our f0 data, these are:</p>
<ul>
<li><p>The ‘upper’ level: Between-speaker variation in mean f0. This can be thought of like variation in <span class="math inline">\(\mu_{speaker}\)</span>. Speaker’s have an average f0 (<span class="math inline">\(\mu_{speaker}\)</span>) that they produce over time. However, speakers are chosen randomly from a larger population, and so any given speaker’s <span class="math inline">\(\mu_{speaker}\)</span> is unpredictable a priori.</p></li>
<li><p>The ‘lower’ level: Within-speaker variation, analogous to <span class="math inline">\(\varepsilon\)</span>. When an individual speaker produces speech, their productions will vary around their average from token to token. Our model cannot explain this and so this is ‘error’</p></li>
</ul>
<p>As seen in the figure above, the variation at the lower and upper levels are analogous. Just like individual speakers will rarely have an average f0 exactly like the population average, individual speakers will rarely produce f0 values exactly at their speaker average. Importantly, variation at the two levels is independent and logically distinct: within-speaker variation can be small or large independently of whether between-speaker variation is large or small.</p>
<p>Basically, each subject’s productions form a little normal distribution around their average, and the mix of these little distributions results in the overall ‘big’ distribution of data across all subjects. By using multilevel models, we can estimate the effects of multiple sources of variation at the same time.</p>
</div>
</div>
<div id="estimating-a-multilevel-model-with-brms" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Estimating a multilevel model with <code>brms</code></h2>
<p>We are now going to fit the same model we fit above, but with a structure that reflects the repeated-measures nature of the data.</p>
<div id="the-model-1" class="section level3" number="2.4.1">
<h3><span class="header-section-number">2.4.1</span> The model</h3>
<p>To specify a multilevel model, you need to write a slightly more complicated model formula. This explanation assumes that you have a dataframe or matrix where one column contains the variable you are interested and predicting (in this case <code>f0</code>), and another column contains a vector containing unique labels for each speaker or source of data (in this case a unique speaker label <code>uspeaker</code>).</p>
<p>To indicate that your model contains an ‘upper’ level where you have clusters of data coming from different individuals, you have to put another model inside your main model!</p>
<p>Before, the model formula looked like this:</p>
<p><code>f0 ~ 1</code></p>
<p>which meant ‘predict f0 using only an intercept’. Now the model formula will look like this:</p>
<p><code>f0 ~ 1 + ( 1 | uspeaker)</code></p>
<p>When you place a predictor in the formula in parenthesis, on the right-hand-side of a pipe, like this <code>( | predictor )</code>, you tell <code>brm</code> that you expect data to be clustered according to each category represented in the grouping vector. In this case, we are telling <code>brm</code> that each unique speaker is a cluster of data. Whatever you put in the left-hand-side of the parentheses <code>( in here | predictor )</code> is the model for each subcluster!</p>
<p>So what does this model formula mean: <code>f0 ~ 1 + ( 1 | uspeaker)</code>? It tells <code>brm</code>: predict f0 based on only an intercept, and also calculate a separate intercept for each speaker. Effectively, this model formula is telling <code>brm</code> to figure out all the information presented in the figures above.</p>
<p>This regression model is now something like this:</p>
<p><span class="math display" id="eq:24">\[
y = \mu_{overall} + \mu_{speaker}+\varepsilon
\tag{2.4}
\]</span></p>
<p>Recall that when we predict an intercept in a regression model, we actually perform the following decomposition <span class="math inline">\(\mu=parameter*1\)</span>. This means that we are actually just fitting a parameter that we expect to equal the value of the <span class="math inline">\(\mu\)</span> we are interested in.</p>
<p>Below, where I have decomposed each <span class="math inline">\(\mu\)</span> into its constituent ‘predictors’ (1) and parameters (<span class="math inline">\(a, b\)</span>).</p>
<p><span class="math display" id="eq:25">\[
y = a*1 + b_{speaker}*1 + \varepsilon
\tag{2.5}
\]</span></p>
<p>In addition to the coefficient estimating the overall intercept (<span class="math inline">\(a\)</span>), we know have another term <span class="math inline">\(b_{speaker}\)</span>. This coefficient is actually a set of coefficients since it has a different value for each speaker (its a vector). It has a different value for each speaker because it will reflect variation in <span class="math inline">\(\mu_{speaker}\)</span>. However, <span class="math inline">\(\mu_{speaker}\)</span> is a random variable since it reflects the random average f0 of each person drawn from the population. If <span class="math inline">\(\mu_{speaker}\)</span> behaves like a random variable, then the coefficients that reflect this value in our model (<span class="math inline">\(b_{speaker}\)</span>) will behave in the same way.</p>
<p>This means that actually our model has <em>two</em> random variables. The first one is the error term <span class="math inline">\(\varepsilon \sim \mathcal{N}(0,\sigma_{error})\)</span>, which has a mean of 0 and a standard deviation which we can refer to as <span class="math inline">\(\sigma_{error}\)</span>. The second is the random, speaker-specific intercepts, or by-speaker intercepts, that can also be thought of as random draw from a normal distribution.</p>
<p>A careful consideration of the model in equation 2.4 suggests that this model wouldn’t really work. If the overall mean is 220 Hz and a speaker’s average is 230, this would suggest a predicted average of 450 (<span class="math inline">\(\mu_{overall} + \mu_{speaker}\)</span>) for this speaker. Clearly that is not how the model should be working.</p>
<p>Recall that I previously said that regression models encode <em>differences</em>. Our model already encodes the overall data average in the <span class="math inline">\(\mu_{overall}\)</span> parameter. Thus, the speaker-specific averages only need to contain information about <em>differences</em> to this overall average. As a result, the model parameters for mean f0 across all speakers will be centered at 0 (i.e., the average), and will tend to be normally distributed with a population-specific standard deviation.</p>
<p>Since our model parameters represent speaker-specific deviations rather than their actual mean f0s, people often use this symbol, <span class="math inline">\(\gamma\)</span>, for them instead of <span class="math inline">\(\mu\)</span>, where <span class="math inline">\(\gamma = \mu_{speaker} - \mu_{overall}\)</span>. We can show the expected distribution of this variable below, where <span class="math inline">\(\sigma_{speakers}\)</span> is a population-specific standard deviation term.</p>
<p><span class="math display" id="eq:26">\[
\gamma_{uspeaker} \sim \mathcal{N}(0,\sigma_{speakers})
\tag{2.6}
\]</span></p>
<p>Our overall model is now as shown below, made specific for the data we have, and using expected parameter names.</p>
<p><span class="math display">\[
\begin{split}
f0 = Intercept + \gamma_{uspeaker} + \varepsilon  \\
\gamma_{uspeaker} \sim \mathcal{N}(0,\sigma_{speakers}) \\
\varepsilon \sim \mathcal{N}(0,\sigma_{error}) \\
\end{split}
\]</span></p>
<p>Each line in the model says the following:</p>
<ul>
<li><p>f0 is equal to the sum the intercept, a speaker-specific deflection from the intercept, and error.</p></li>
<li><p>the speaker intercepts are drawn from a normal distribution with a mean of 0 and a standard deviation of <span class="math inline">\(\sigma_{speakers}\)</span>. This distribution represents the random variation of speakers around the average f0 for the population.</p></li>
<li><p>the error is also drawn from a normal distribution with a mean of 0 and a standard deviation of <span class="math inline">\(\sigma_{error}\)</span>. This distribution represents the random within-speaker variation of productions around the average f0 for the speaker.</p></li>
</ul>
<p>There is a very important difference in how the initial and final models we fit view and partition the variation in our model. The initial model we fit viewed the variation in the model like this:</p>
<p><span class="math display" id="eq:28">\[
\sigma_{total} = \sigma_{error}
\tag{2.7}
\]</span></p>
<p>In other words, all variation was error. We don’t know why values vary from the mean. Our multilevel model views the variation in our data like this:</p>
<p><span class="math display" id="eq:29">\[
\sigma_{total} = \sigma_{speaker} + \sigma_{error}
\tag{2.8}
\]</span></p>
<p>It sees only <em>some</em> of the variation in data as error. Basically, from the perspective of this multilevel model, the variation in the data is a combination of random (but systematic) between-speaker variation, and random within-speaker variation.</p>
</div>
<div id="fitting-the-model" class="section level3" number="2.4.2">
<h3><span class="header-section-number">2.4.2</span> Fitting the model</h3>
<p>We can fit a model with a formula that appropriately specifies the clustering we expect in our data. As a result, this model can estimate both between- and within-speaker variability.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb91-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb91-2" aria-hidden="true" tabindex="-1"></a>multilevel_model <span class="ot">=</span>  </span>
<span id="cb91-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb91-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (f0 <span class="sc">~</span> (<span class="dv">1</span><span class="sc">|</span>uspeaker), <span class="at">data =</span> w, <span class="at">chains =</span> <span class="dv">1</span>, <span class="at">cores =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="do">## loand and inspect pre-fit model</span></span>
<span id="cb92-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb92-2" aria-hidden="true" tabindex="-1"></a>multilevel_model <span class="ot">=</span> <span class="fu">readRDS</span> (<span class="st">&quot;2_multilevel_model.RDS&quot;</span>)</span>
<span id="cb92-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb92-3" aria-hidden="true" tabindex="-1"></a>multilevel_model</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: f0 ~ (1 | uspeaker) 
##    Data: w (Number of observations: 576) 
## Samples: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 1000
## 
## Group-Level Effects: 
## ~uspeaker (Number of levels: 48) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)    20.19      2.10    16.65    25.06 1.00      135      192
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   220.39      3.10   214.49   226.13 1.03       51      108
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    12.54      0.39    11.83    13.34 1.01      400      700
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>This new model contains one new chunk its print statement:</p>
<pre><code>Group-Level Effects: 
~uspeaker (Number of levels: 48) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)    20.19      2.10    16.65    25.06 1.00      135      192</code></pre>
<p>This sections contains information about the standard deviation of between-speaker averages (<span class="math inline">\(\mu_{speaker}\)</span>) in the sample. We can see that the information provided by <code>brms</code> is quite similar to what we can estimate directly using our data. However, <em>brms</em> does this all for us, in addition to giving us a lot more information.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="do">## find mean f0 for each speaker</span></span>
<span id="cb95-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb95-2" aria-hidden="true" tabindex="-1"></a>speaker_means <span class="ot">=</span> <span class="fu">aggregate</span> (f0 <span class="sc">~</span> uspeaker, <span class="at">data =</span> w, <span class="at">FUN =</span> mean) </span>
<span id="cb95-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb95-3" aria-hidden="true" tabindex="-1"></a><span class="do">## find the within speaker variance. This is the within-talker &#39;error&#39;.</span></span>
<span id="cb95-4"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb95-4" aria-hidden="true" tabindex="-1"></a>speaker_vars <span class="ot">=</span> <span class="fu">aggregate</span> (f0 <span class="sc">~</span> uspeaker, <span class="at">data =</span> w, <span class="at">FUN =</span> var) </span>
<span id="cb95-5"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb95-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-6"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb95-6" aria-hidden="true" tabindex="-1"></a><span class="do">## the mean of the speaker means corresponds to our overall mean estimate</span></span>
<span id="cb95-7"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb95-7" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span> (speaker_means<span class="sc">$</span>f0)</span></code></pre></div>
<pre><code>## [1] 220.401</code></pre>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="do">## sd(Intercept) in the model reflects the amount of variation in talker </span></span>
<span id="cb97-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="do">## intercepts. This is the between speaker variation in our model. See how it is </span></span>
<span id="cb97-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb97-3" aria-hidden="true" tabindex="-1"></a><span class="do">## similar to the sd of the actual speaker means.</span></span>
<span id="cb97-4"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb97-4" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span> (speaker_means<span class="sc">$</span>f0)</span></code></pre></div>
<pre><code>## [1] 20.07397</code></pre>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="do">## sigma in the model reflects the amount of variation in talker intercepts.</span></span>
<span id="cb99-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="do">## This is the between speaker variation in our model. </span></span>
<span id="cb99-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb99-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span> (<span class="fu">sd</span> (speaker_vars<span class="sc">$</span>f0))</span></code></pre></div>
<pre><code>## [1] 12.42719</code></pre>
<p>The overall mean f0 in our data (220.4) corresponds quite well to our model estimate of 220.4. This reflects the central location of the overall distribution below (the horizontal line in the figure below). The standard deviation of the speaker means (Intercept = 20.1) is again very similar to our model estimate (sd(Intercept) = 20.1). This reflects the average distance from each speaker’s average, and the overall average. Finally, the average of the within speaker standard deviation in our data (12.4) corresponds closely to our model’s error estimate (sigma = 12.5). This reflects the average spread of each speaker’s data relative to their own mean, within their own little boxplot.</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">1</span>))</span>
<span id="cb101-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb101-2" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (f0 <span class="sc">~</span> uspeaker, <span class="at">data =</span> w, <span class="at">main =</span> <span class="st">&quot;Speaker Boxplots&quot;</span>,<span class="at">col=</span><span class="fu">c</span>(yellow,coral,</span>
<span id="cb101-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb101-3" aria-hidden="true" tabindex="-1"></a>         deepgreen,teal)) </span>
<span id="cb101-4"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb101-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h =</span> <span class="fl">220.4</span>, <span class="at">lwd=</span><span class="dv">3</span>,<span class="at">lty=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="week-2_files/figure-html/unnamed-chunk-17-1.png" width="768" /></p>
</div>
</div>
<div id="checking-model-convergence" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Checking model convergence</h2>
<p>Remember that our model parameter estimates consist of a set of samples from the posterior distribution of a parameter. If we don’t take enough of these samples, our parameter estimates will be unreliable.</p>
<p>For this reason, it’s important to look at the ESS values (the ‘expected sample size’), and the ‘Rhat’ values provided by <code>brm</code>. ESS tells you about how many independent samples you have taken from the likelihood. Bulk ESS is how many samples the sampler took in the thick part of the density, and Tail ESS reflects how much time the sampler spent in the thin part, the ‘tails’. Rhat tells you about whether your ‘chains’ have converged (more on this later). As noted above, values of Rhat near 1 are good, and values higher than around 1.1 are a bad sign.</p>
<p>We haven’t really taken many samples here, so we can’t be confident in our parameter estimates. Ideally we would like several hundred samples (at least) for mean estimates, and thousands to be confident in the 95% confidence intervals.</p>
<p>To get more samples we can run the model longer, or we can use more <em>chains</em>. A chain is basically a separate set of samples for your parameter values. Just imagine you had estimated the model 4 times in a row and mixed your estimations. A model can be fit in parallel across several chains, and then the estimates can be merged across chains. When you do this across multiple cores, you can get N times as many samples when you use N cores. Since many computers these days have 4-8 (or more) cores, we can take advantage of parallel processing to fit models faster.</p>
<p>Below, I refit the same model from above but run it on 4 chains, and on 4 cores at once. This doesn’t take any longer but it does give us a higher ESS. Just make sure you leave a couple of cores free on your computer when you fit a model!</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb102-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb102-2" aria-hidden="true" tabindex="-1"></a>multilevel_multicore <span class="ot">=</span>  </span>
<span id="cb102-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb102-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (f0 <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>uspeaker), <span class="at">data =</span> w, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>)</span></code></pre></div>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="do">## load and inspect pre-fit model</span></span>
<span id="cb103-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb103-2" aria-hidden="true" tabindex="-1"></a>multilevel_multicore <span class="ot">=</span> <span class="fu">readRDS</span> (<span class="st">&#39;2_multilevel_multicore.RDS&#39;</span>)</span>
<span id="cb103-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb103-3" aria-hidden="true" tabindex="-1"></a>multilevel_multicore</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: f0 ~ 1 + (1 | uspeaker) 
##    Data: w (Number of observations: 576) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~uspeaker (Number of levels: 48) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)    20.22      2.19    16.54    25.19 1.02      345      615
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   220.47      2.91   214.67   226.14 1.02      228      543
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    12.54      0.39    11.81    13.34 1.00     3427     2943
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>If we compare the ESS for this new model to the previous model, we see that using 4 chains has substantially increased our ESS, without taking up any more computing time.</p>
<p>One final tweak that I will be using going forward is to ‘thin’ samples. Notice that we have collected ‘total post-warmup samples = 4000’. This means our model has 4000 samples for every parameter in the model. However, we have only about 400 ‘effective samples’ to show for it for some parameters of interest. This means that a lot of our samples are basically dead weight, taking up space and slowing down computations for no good reason.</p>
<p>Sometimes consecutive samples can be too similar and so don’t given you that much independent information. A way to fix this is to run longer chains and keep only every nth one. This lets your models be smaller while containing approximately the same information.</p>
<p>To do this you have to set the <code>iter</code>, <code>warmup</code> and <code>thin</code> parameters. You will keep every sample after the warmup is done, up to the <code>iter</code> maximum. So if <code>iter=3000</code> and <code>warmup=1000</code> you will end up with 2000 samples. After this, you keep only one every <code>thin</code> samples. Basically, you will end up with <span class="math inline">\((iter-warmup) / thin\)</span> samples per chain.</p>
<p>Below, I ask for 11,000 sample per chain, 10,000 post warm-up. However, since I plan to keep only 1/10, I will have 1000 per core, so 4000 samples in total. However, despite having the same number of samples as the <code>multilevel_multicore</code>, the ESS for this model is much higher for important parameters such as the model intercept.</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb105-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb105-2" aria-hidden="true" tabindex="-1"></a>multilevel_thinned <span class="ot">=</span>  </span>
<span id="cb105-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb105-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (f0 <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>uspeaker), <span class="at">data =</span> w, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>,</span>
<span id="cb105-4"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb105-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">warmup =</span> <span class="dv">1000</span>, <span class="at">iter =</span> <span class="dv">11000</span>, <span class="at">thin =</span> <span class="dv">10</span>)</span></code></pre></div>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="do">## load and inspect pre-fit model</span></span>
<span id="cb106-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb106-2" aria-hidden="true" tabindex="-1"></a>multilevel_thinned <span class="ot">=</span> <span class="fu">readRDS</span> (<span class="st">&#39;2_multilevel_thinned.RDS&#39;</span>)</span>
<span id="cb106-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb106-3" aria-hidden="true" tabindex="-1"></a>multilevel_thinned</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: f0 ~ 1 + (1 | uspeaker) 
##    Data: w (Number of observations: 576) 
## Samples: 4 chains, each with iter = 11000; warmup = 1000; thin = 10;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~uspeaker (Number of levels: 48) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)    20.06      2.23    16.24    24.98 1.00     2775     3392
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   220.40      2.95   214.57   226.19 1.00     1987     2625
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    12.54      0.38    11.81    13.31 1.00     3908     3891
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<div id="specifying-prior-probabilities" class="section level2" number="2.6">
<h2><span class="header-section-number">2.6</span> Specifying prior probabilities</h2>
<p>In Chapter 1 we discussed that Bayesian models require that prior probabilities be specified for all parameters. You may have noticed that to this point I haven’t discussed priors at all.</p>
<p>If you don’t specify prior probabilities for your parameters, <code>brm</code> will use a ‘flat’ prior for all parameters. When you do this, you are basically relying only on the likelihood for your analysis. You are also telling your model that, a priori, <em>any</em> value of average f0 is equally believable. Empirically, this is false. As a practical matter this can cause problems for samplers like <code>brm</code> (STAN actually). Basically, the sampler has a harder time figuring out the most likely values when you tell it to look anywhere from positive to negative infinity. Even a bit of guidance can help.</p>
<p><code>brms</code> makes it really easy to specify prior probabilities for specific parameters or whole groups of parameters. First we figure out the overall mean and the standard deviation of the data.</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(f0s)</span></code></pre></div>
<pre><code>## [1] 220.401</code></pre>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(f0s)</span></code></pre></div>
<pre><code>## [1] 23.22069</code></pre>
<p>In the example below, I use this information to set reasonable bounds on the parameters in the model. I do this by class of parameter:</p>
<ul>
<li>Intercept: this is a unique class, only for intercepts.</li>
<li>b: this is for all the non-intercept predictors. There are none in this model.</li>
<li>sd: this is for all standard deviation parameters. In our example this is <code>sd(Intercept)</code> for <code>uspeaker</code> (<span class="math inline">\(\sigma_{speaker}\)</span>), and <code>sigma</code> (<span class="math inline">\(\sigma_{error}\)</span>).</li>
</ul>
<p>Both priors below use a ‘t’ distribution, which is just like a normal distribution but it is more pointy, and has more density in the outer parts of the distribution. I use this because it has good properties, but you can use normal priors, or any other priors that you think work for your model. Rather than focusing on the mathematical properties of priors, the most important thing is that their <em>shape</em> reflect the distribution of credible parameter values a priori (before you conducted your experiment).</p>
<p>The format for the priors looks like this <code>student_t(nu, mean, sd)</code>, where <code>nu</code> is a parameter that determines how pointy the distribution is, and <code>mean</code> and <code>sd</code> are the same mean and standard deviation parameters from the normal distribution. The nu parameter ranges from 1 to infinity, and large numbers result in a more normal-like distribution.</p>
<p>So, for the overall intercept (<span class="math inline">\(\mu_{overall}\)</span>) I am using a prior with the same mean as the data mean, and a standard deviation that is twice as large as the data standard deviation. For both the model standard deviation terms (<span class="math inline">\(\sigma_{error}, \sigma_{speaker}\)</span>) I am using a t distribution centered at 0 (explained below), with a standard deviation twice as large as the data standard deviation.</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb112-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-2" aria-hidden="true" tabindex="-1"></a>multilevel_priors <span class="ot">=</span>  </span>
<span id="cb112-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (f0 <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>uspeaker), <span class="at">data =</span> w, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>,</span>
<span id="cb112-4"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">warmup =</span> <span class="dv">1000</span>, <span class="at">iter =</span> <span class="dv">11000</span>, <span class="at">thin =</span> <span class="dv">10</span>,</span>
<span id="cb112-5"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 220.4, 46.4)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb112-6"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb112-6" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 46.4)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sd&quot;</span>)))</span></code></pre></div>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="do">## load and inspect pr-fit model</span></span>
<span id="cb113-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb113-2" aria-hidden="true" tabindex="-1"></a>multilevel_priors <span class="ot">=</span> <span class="fu">readRDS</span> (<span class="st">&#39;2_multilevel_priors.RDS&#39;</span>)</span>
<span id="cb113-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb113-3" aria-hidden="true" tabindex="-1"></a>multilevel_priors</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: f0 ~ 1 + (1 | uspeaker) 
##    Data: w (Number of observations: 576) 
## Samples: 4 chains, each with iter = 11000; warmup = 1000; thin = 10;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~uspeaker (Number of levels: 48) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)    20.19      2.24    16.29    25.06 1.00     3114     3663
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   220.42      2.97   214.44   226.38 1.00     1796     2841
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    12.54      0.39    11.81    13.34 1.00     3968     3972
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>In the left panel below (plot code at end of chapter) I compare the t distribution we used (blue) to the equivalent normal distribution (red). It is clear that the t distribution can tolerate more extreme values because of its ‘fatter’ tails. As we will discuss later, using t distributions can make our models more robust to outliers. This is really important in linguistics where subjects/speakers sometimes do weird stuff!</p>
<p>In the middle panel we compare this prior to the data, and see that the prior distribution is much broader (more vague) than the data distribution. The right panel compares the prior for the standard deviation parameters to the absolute value of the centered f0 data. This presentation shows how far each observation is from the mean f0 (at 220 Hz). Again, the prior distribution we have assigned for these parameters is much larger than the variation in the data. As a result, neither of these priors is going to have much of an effect on our parameter estimates.</p>
<p><img src="week-2_files/figure-html/unnamed-chunk-25-1.png" width="768" /></p>
<p>If we compare the output of this model to <code>multilevel_thinned</code>, we see that specifying a prior has has no noticeable effect on our results. This is because the prior matters less and less when you have a lot of data, and because we have set wide priors that are appropriate (but vague) given our data. Although the priors may not matter much for models as simple as these, they can be very important when working with more complex data, and are a necessary component of Bayesian modeling.</p>
</div>
<div id="answering-our-research-questions" class="section level2" number="2.7">
<h2><span class="header-section-number">2.7</span> Answering our research questions</h2>
<p>Let’s return again to the research questions I posed initially:</p>
<ol style="list-style-type: decimal">
<li><p>What is the average f0 of the whole <em>population</em> likely to be?</p></li>
<li><p>Can we set bounds on likely mean f0 values based on the data we collected?</p></li>
</ol>
<p>And we can compare the answers provided to this question by our initial and final models.</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb115-1" aria-hidden="true" tabindex="-1"></a>model</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: f0 ~ 1 
##    Data: w (Number of observations: 576) 
## Samples: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 1000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   220.40      0.97   218.33   222.30 1.00      851      557
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    23.24      0.69    21.99    24.61 1.00      653      550
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb117-1" aria-hidden="true" tabindex="-1"></a>multilevel_priors</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: f0 ~ 1 + (1 | uspeaker) 
##    Data: w (Number of observations: 576) 
## Samples: 4 chains, each with iter = 11000; warmup = 1000; thin = 10;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~uspeaker (Number of levels: 48) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)    20.19      2.24    16.29    25.06 1.00     3114     3663
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   220.42      2.97   214.44   226.38 1.00     1796     2841
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    12.54      0.39    11.81    13.34 1.00     3968     3972
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Our initial model (<code>model</code>) and our final model (<code>multilevel_priors</code>) agree on what the average f0 is. However, they disagree on a credible interval for that parameter. Our initial model did not specify information about repeated measures. This causes our model to think that it has more independent observations than it does, and so it returns an overly-precise estimate.</p>
<p>Another difference is that the final model has a much smaller <code>sigma</code> parameter (12.5 vs 23.2). This indicates that the error (<span class="math inline">\(\varepsilon\)</span>) is much smaller in the final model than in the initial model. Keep in mind that ‘error’ is just what your model can’t explain. Our final model explains much more and so there is less error. The reduced error is a direct result of the fact that the final model splits random variation up into between-speaker and within-speaker components, estimating the between-speaker variation (<span class="math inline">\(sigma_{speaker}\)</span>) to be about 20 Hz.</p>
<p>Usually, when I report parameters I provide the mean and standard deviations of the posterior distribution, in addition to the bounds of the 95% credible interval of the parameter. Based on the result of our final model, I think a thorough description of the general properties of our data might go something like:</p>
<blockquote>
<p>"Based on our model the average f0 produced by adult females in Michigan is likely to be 220 Hz (s.d. = 2.97, 95% CI = 214.4, 226.4). However, consistent between-speaker variation averages about 20 Hz (s.d. = 2.24, 95% CI = 16.29, 25.06), meaning that we can expect the average f0 produced by individuals to deviate substantially from 220 Hz. Finally, the standard deviation of production error was about 12.5 Hz (s.d. = 0.39, 95% CI = 11.81, 13.34) indicating that the amount of random between speaker variation in production is about half the magnitude of the stable, between-speaker differences in f0.</p>
</blockquote>
<p>I am including the speaker boxplots below because I think this image basically presents the same information as the paragraph above, but in visual form. In general, any data relationship or result can be presented in a figure, and the relationships presented in a figure can also be expressed as a mathematical model.</p>
<p>When you are thinking about the relationships in your data, or that you expect in your data, its a good idea to think: what kind of picture could illustrate this relationship? Conversely, if you see a figure of your results that you feel really expresses something interesting about your data you should think, how can these relationships be represented in a model?</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">1</span>))</span>
<span id="cb119-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb119-2" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (f0 <span class="sc">~</span> uspeaker, <span class="at">data =</span> w, <span class="at">main =</span> <span class="st">&quot;Speaker Boxplots&quot;</span>,<span class="at">col=</span><span class="fu">c</span>(yellow,coral,</span>
<span id="cb119-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb119-3" aria-hidden="true" tabindex="-1"></a>         deepgreen,teal)) </span>
<span id="cb119-4"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb119-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h =</span> <span class="fl">220.4</span>, <span class="at">lwd=</span><span class="dv">3</span>,<span class="at">lty=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="week-2_files/figure-html/unnamed-chunk-27-1.png" width="768" /></p>
</div>
<div id="plot-code-1" class="section level2" number="2.8">
<h2><span class="header-section-number">2.8</span> Plot Code</h2>
<p>Plot for comparison of prior distributions with f0 data</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get t density</span></span>
<span id="cb120-2"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-2" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">seq</span> (<span class="sc">-</span><span class="dv">4</span>,<span class="dv">4</span>,.<span class="dv">1</span>)</span>
<span id="cb120-3"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-3" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">=</span> <span class="fu">dt</span> (x1, <span class="dv">3</span>); y1 <span class="ot">=</span> y1 <span class="sc">/</span> <span class="fu">max</span> (y1) <span class="sc">/</span> <span class="dv">50</span></span>
<span id="cb120-4"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-4" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="dv">220</span><span class="sc">+</span>(x1<span class="sc">*</span><span class="fl">46.4</span>)</span>
<span id="cb120-5"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-5" aria-hidden="true" tabindex="-1"></a>y2 <span class="ot">=</span> <span class="fu">dnorm</span> (x2, <span class="dv">220</span>, <span class="fl">46.4</span>); y2 <span class="ot">=</span> y2 <span class="sc">/</span> <span class="fu">max</span> (y2) <span class="sc">/</span> <span class="dv">50</span></span>
<span id="cb120-6"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-7"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-7" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb120-8"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-8" aria-hidden="true" tabindex="-1"></a><span class="do">## plot t</span></span>
<span id="cb120-9"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span> (x2, y1, <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">ylab =</span> <span class="st">&#39;Density&#39;</span>, <span class="at">xlab =</span> <span class="st">&#39;f0&#39;</span>, <span class="at">col =</span> <span class="dv">4</span>)</span>
<span id="cb120-10"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-10" aria-hidden="true" tabindex="-1"></a><span class="do">## compare to equivalent normal</span></span>
<span id="cb120-11"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-11" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span> (x2, y2, <span class="at">lwd=</span><span class="dv">2</span>,<span class="at">col=</span><span class="dv">2</span>)</span>
<span id="cb120-12"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-13"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-13" aria-hidden="true" tabindex="-1"></a><span class="do">## plot t</span></span>
<span id="cb120-14"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span> (x2, y1, <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">ylab =</span> <span class="st">&#39;Density&#39;</span>, <span class="at">xlab =</span> <span class="st">&#39;f0&#39;</span>, <span class="at">col =</span> <span class="dv">4</span>)</span>
<span id="cb120-15"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-15" aria-hidden="true" tabindex="-1"></a><span class="do">## compare to equivalent normal</span></span>
<span id="cb120-16"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-16" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span> (f0s, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">freq =</span> <span class="cn">FALSE</span>)</span>
<span id="cb120-17"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-18"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-18" aria-hidden="true" tabindex="-1"></a><span class="do">## plot prior for standard deviations</span></span>
<span id="cb120-19"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-19" aria-hidden="true" tabindex="-1"></a>x3 <span class="ot">=</span> x2 <span class="sc">-</span> <span class="fu">mean</span> (x2)</span>
<span id="cb120-20"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-20" aria-hidden="true" tabindex="-1"></a>y3 <span class="ot">=</span> <span class="fu">dt</span> (x1, <span class="dv">3</span>); y3 <span class="ot">=</span> y3 <span class="sc">/</span> <span class="fu">max</span> (y3) <span class="sc">/</span> <span class="dv">20</span></span>
<span id="cb120-21"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-21" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span> (x3[x3<span class="sc">&gt;</span><span class="dv">0</span>], y3[x3<span class="sc">&gt;</span><span class="dv">0</span>], <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">ylab =</span> <span class="st">&#39;Density&#39;</span>, </span>
<span id="cb120-22"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-22" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&#39;f0&#39;</span>, <span class="at">col =</span> <span class="dv">4</span>)</span>
<span id="cb120-23"><a href="inference-for-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#cb120-23" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span> (<span class="fu">abs</span> (f0s <span class="sc">-</span> <span class="fu">mean</span> (f0s)), <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">freq =</span> <span class="cn">FALSE</span>)</span></code></pre></div>

</div>
</div>
<!-- Default Statcounter code for statsbook
https://santiagobarreda.github.io/stats-class/ -->
<script type="text/javascript">
var sc_project=12454226; 
var sc_invisible=1; 
var sc_security="a1959418"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12454226/0/a1959418/1/"
alt="Web Analytics"></a></div></noscript>
<!-- End of Statcounter Code -->
            </section>

          </div>
        </div>
      </div>
<a href="inspecting-a-single-sample-of-values.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="comparing-two-groups.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
